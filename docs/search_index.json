[["index.html", "Simulation Book Overview", " Simulation Book 2021-06-08 Overview Tutorials on data simulation from the 2021 PsyPAG Simulation Summer School. "],["intro-to-faux.html", "Chapter 1 Intro to Faux 1.1 Multivariate normal 1.2 Factorial Designs 1.3 Replications", " Chapter 1 Intro to Faux library(tidyverse) library(faux) library(broom) library(afex) set.seed(8675309) # Jenny, I&#39;ve got your number In this tutorial, we’ll learn how to simulate data for factorial designs using {faux}. There are more extensive examples at https://debruine.github.io/faux/. 1.1 Multivariate normal You can create sets of correlated normally distributed values using rnorm_multi(). dat3 &lt;- rnorm_multi( n = 50, vars = 3, mu = c(1, 2, 3), sd = c(0.5, 1, 1.5), r = c(0, .25, .5), varnames = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) ) The function get_params() gives you a quick way to see the means, SDs and correlations in the simulated data set to make sure you set the parameters correctly. get_params(dat3) n var A B C mean sd 50 A 1.00 0.01 0.31 1.00 0.42 50 B 0.01 1.00 0.38 1.93 0.92 50 C 0.31 0.38 1.00 2.85 1.31 If you set empirical to TRUE, the values you set will be the sample parameters, not the population parameters. This isn’t usually what you want for a simulation, but can be useful to check you set the parameters correctly. dat3 &lt;- rnorm_multi( n = 50, vars = 3, mu = c(1, 2, 3), sd = c(0.5, 1, 1.5), r = c(0, .25, .5), varnames = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), empirical = TRUE ) get_params(dat3) n var A B C mean sd 50 A 1.00 0.0 0.25 1 0.5 50 B 0.00 1.0 0.50 2 1.0 50 C 0.25 0.5 1.00 3 1.5 1.1.1 Shortcuts There are a few shortcuts you can use. Run the following and see if you can guess how they work. guess1 &lt;- rnorm_multi(50, mu = c(x = 1, y = 2, z = 3), empirical = TRUE) get_params(guess1) n var x y z mean sd 50 x 1 0 0 1 1 50 y 0 1 0 2 1 50 z 0 0 1 3 1 guess2 &lt;- rnorm_multi(50, vars = 4, r = 0.5, empirical = TRUE) get_params(guess2) n var X1 X2 X3 X4 mean sd 50 X1 1.0 0.5 0.5 0.5 0 1 50 X2 0.5 1.0 0.5 0.5 0 1 50 X3 0.5 0.5 1.0 0.5 0 1 50 X4 0.5 0.5 0.5 1.0 0 1 iris_r &lt;- cor(iris[, 1:4]) iris_mu &lt;- summarise_all(iris[, 1:4], mean) %&gt;% t() iris_sd &lt;- summarise_all(iris[, 1:4], sd) %&gt;% t() guess3 &lt;- rnorm_multi(50, mu = iris_mu, sd = iris_sd, r = iris_r) get_params(guess3) n var Sepal.Length Sepal.Width Petal.Length Petal.Width mean sd 50 Sepal.Length 1.00 -0.19 0.84 0.81 6.03 0.77 50 Sepal.Width -0.19 1.00 -0.57 -0.49 3.10 0.50 50 Petal.Length 0.84 -0.57 1.00 0.97 3.90 1.79 50 Petal.Width 0.81 -0.49 0.97 1.00 1.25 0.76 You can set the r for correlations in a few different ways. If all correlations have the same value, just set r equal to a single number. # all correlations the same value rho_same &lt;- rnorm_multi(50, 4, r = .5, empirical = TRUE) get_params(rho_same) n var X1 X2 X3 X4 mean sd 50 X1 1.0 0.5 0.5 0.5 0 1 50 X2 0.5 1.0 0.5 0.5 0 1 50 X3 0.5 0.5 1.0 0.5 0 1 50 X4 0.5 0.5 0.5 1.0 0 1 You can set rho to a vector or matrix of the full correlation matrix. This is convenient when you’re getting the values from an existing dataset, where you can just use the output of the cor() function. # full correlation matrix # X1 X2 X3 X4 rho &lt;- c(1.0, 0.5, 0.4, 0.3, # X1 0.5, 1.0, 0.2, 0.1, # X2 0.4, 0.2, 1.0, 0.0, # X3 0.3, 0.1, 0.0, 1.0) # X4 rho_cormat &lt;- rnorm_multi(50, 4, r = rho, empirical = TRUE) get_params(rho_cormat) n var X1 X2 X3 X4 mean sd 50 X1 1.0 0.5 0.4 0.3 0 1 50 X2 0.5 1.0 0.2 0.1 0 1 50 X3 0.4 0.2 1.0 0.0 0 1 50 X4 0.3 0.1 0.0 1.0 0 1 Alternatively, you can just specify the values from the upper right triangle of a correlation matrix. This is easier if you’re reading the values out of a paper. # upper right triangle # X2 X3 X4 rho &lt;- c(0.5, 0.4, 0.3, # X1 0.2, 0.1, # X2 0.0) # X3 rho_urt &lt;- rnorm_multi(50, 4, r = rho, empirical = TRUE) get_params(rho_urt) n var X1 X2 X3 X4 mean sd 50 X1 1.0 0.5 0.4 0.3 0 1 50 X2 0.5 1.0 0.2 0.1 0 1 50 X3 0.4 0.2 1.0 0.0 0 1 50 X4 0.3 0.1 0.0 1.0 0 1 1.2 Factorial Designs You can use rnorm_multi() to simulate data for each between-subjects cell of a factorial design and manually combine the tables, but faux has a function that better maps onto how we usually think and teach about factorial designs. The default design is 100 observations of one variable (named y) with a mean of 0 and SD of 1. Unless you set plot = FALSE or run faux_options(plot = FALSE), this function will show you a plot of your design so you can check that it looks like you expect. simdat1 &lt;- sim_design() 1.2.1 Factors Use lists to set the names and levels of within- and between-subject factors. pettime &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)) ) You can set mu and sd with unnamed vectors, but getting the order right can take some trial and error. pettime &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), mu = 1:6 ) You can set values with a named vector for a single type of factor. The values do not have to be in the right order if they’re named. pettime &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), mu = c(cat = 1, ferret = 5, dog = 3), sd = c(pre = 1, post = 2) ) Or use a data frame for within- and between-subject factors. pettime &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), mu = data.frame( pre = c(1, 3, 5), post = c(2, 4, 6), row.names = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;) ) ) If you have within-subject factors, set the correlations for each between-subject cell like this. pettime &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), r = list(cat = 0.5, dog = 0.25, ferret = 0), empirical = TRUE, plot = FALSE ) get_params(pettime) pet n var pre post mean sd cat 100 pre 1.00 0.50 0 1 cat 100 post 0.50 1.00 0 1 dog 100 pre 1.00 0.25 0 1 dog 100 post 0.25 1.00 0 1 ferret 100 pre 1.00 0.00 0 1 ferret 100 post 0.00 1.00 0 1 You can also change the name of the dv and id columns and output the data in long format. If you do this, you also need to tell get_params() what columns contain the between- and within-subject factors, the dv, and the id. dat_long &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), id = &quot;subj_id&quot;, dv = &quot;score&quot;, long = TRUE, plot = FALSE ) get_params(dat_long, between = &quot;pet&quot;, within = &quot;time&quot;, id = &quot;subj_id&quot;, dv = &quot;score&quot;, digits = 3) pet n var pre post mean sd cat 100 pre 1.000 0.071 -0.001 1.120 cat 100 post 0.071 1.000 0.036 0.875 dog 100 pre 1.000 0.127 -0.036 1.081 dog 100 post 0.127 1.000 0.065 0.976 ferret 100 pre 1.000 0.075 0.072 0.967 ferret 100 post 0.075 1.000 0.035 0.936 The current version of faux doesn’t actually need between or dv and later versions won’t need within or id if a data frame was created with faux. 1.2.2 Anonymous Factors If you need to make a quick demo, you can set factors anonymously with integer vectors. For example, the following code makes 3B*2B*2W mixed design. dat_anon &lt;- sim_design( n = 50, between = c(3, 2), within = 2, mu = 1:12 ) Faux has a quick plotting function for visualising data made with faux. The plot created by sim_design() shows the design, while this function shows the simulated data. plot(dat_anon) You can change the order of plotting and the types of geoms plotted. This takes a little trial and error, so this function will probably be refined in later versions. plot(dat_anon, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;, geoms = c(&quot;violin&quot;, &quot;pointrangeSD&quot;)) 1.3 Replications You often want to simulate data repeatedly to do things like calculate power. The sim_design() function has a lot of overhead for checking if a design makes sense and if the correlation matrix is possible, so you can speed up the creation of multiple datasets with the same design using the rep argument. This will give you a nested data frame with each dataset in the data column. dat_rep &lt;- sim_design( within = 2, n = 20, mu = c(0, 0.25), rep = 5, plot = FALSE ) 1.3.1 Analyse each replicate You can run analyses on the nested data by wrapping your analysis code in a function then using map() to run the analysis on each data set and unnest() to expand the results into a data table. analyse &lt;- function(data) { t.test(data$A1, data$A2, paired = TRUE) %&gt;% broom::tidy() } dat_rep %&gt;% mutate(analysis = map(data, analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) rep estimate statistic p.value parameter conf.low conf.high method alternative 1 -0.1311559 -0.4271395 0.6740791 19 -0.7738319 0.5115202 Paired t-test two.sided 2 -0.2684812 -1.1258509 0.2742492 19 -0.7676038 0.2306414 Paired t-test two.sided 3 -0.3040475 -0.9078698 0.3753187 19 -1.0050056 0.3969106 Paired t-test two.sided 4 -0.5503311 -1.9942297 0.0606779 19 -1.1279257 0.0272635 Paired t-test two.sided 5 -0.1431282 -0.4865269 0.6321583 19 -0.7588616 0.4726051 Paired t-test two.sided 1.3.2 ANOVA Use the same pattern to run an ANOVA on a version of the pettime dataset. First, simulate 100 datasets in long format. These data will have small main effects of pet and time, but no interaction. pettime100 &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;)), n = c(cat = 50, dog = 40), mu = data.frame( pre = c(1, 1.2), post = c(1.2, 1.4), row.names = c(&quot;cat&quot;, &quot;dog&quot;) ), sd = 1, id = &quot;pet_id&quot;, dv = &quot;score&quot;, r = 0.5, long = TRUE, rep = 100 ) Then set up your analysis. We’ll use the aov_ez() function from the {afex} package because its arguments match those of sim_design(). afex::set_sum_contrasts() # avoids annoying afex message ## setting contr.sum globally: options(contrasts=c(&#39;contr.sum&#39;, &#39;contr.poly&#39;)) afex_options(include_aov = FALSE) # runs faster afex_options(es_aov = &quot;pes&quot;) # changes effect size measure to partial eta squared analyse &lt;- function(data) { a &lt;- afex::aov_ez( id = &quot;pet_id&quot;, dv = &quot;score&quot;, between = &quot;pet&quot;, within = &quot;time&quot;, data = data ) # return anova_table for GG-corrected DF as_tibble(a$anova_table, rownames = &quot;term&quot;) %&gt;% mutate(term = factor(term, levels = term)) %&gt;% # keeps terms in order rename(p.value = `Pr(&gt;F)`) # fixes annoying p.value name } Make a table of the results of each analysis: pettime_sim &lt;- pettime100 %&gt;% mutate(analysis = map(data, analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) rep term num Df den Df MSE F pes p.value 1 pet 1 88 1.416 0.667 0.008 0.416 1 time 1 88 0.534 0.544 0.006 0.463 1 pet:time 1 88 0.534 0.035 0.000 0.852 2 pet 1 88 1.178 2.442 0.027 0.122 2 time 1 88 0.498 11.016 0.111 0.001 2 pet:time 1 88 0.498 1.820 0.020 0.181 Then you can summarise the data to calculate things like power for each effect or mean effect size. pettime_sim %&gt;% group_by(term) %&gt;% summarise(power = mean(p.value &lt; 0.05), mean_pes = mean(pes), .groups = &quot;drop&quot;) term power mean_pes pet 0.15 0.0212741 time 0.37 0.0424412 pet:time 0.03 0.0089845 The power for the between-subjects effect of pet is smaller than for the within-subjects effect of time. What happens if you reduce the correlation between pre and post? "],["faux-exercises.html", "A Faux Exercises A.1 Short Exercises A.2 Calorie Placement Re-Simulation", " A Faux Exercises library(tidyverse) library(faux) library(afex) library(emmeans) faux_options(plot = FALSE) set.seed(8675309) A.1 Short Exercises A.1.1 Multivariate normal Sample 40 values of three variables named J, K and L from a population with means of 10, 20 and 30, and SDs of 5. J and K are correlated 0.5, J and L are correlated 0.25, and K and L are not correlated. ex1 &lt;- rnorm_multi(n = 40, mu = c(J = 10, K = 20, L = 30), sd = 5, r = c(0.5, 0.25, 0)) get_params(ex1) n var J K L mean sd 40 J 1.00 0.52 0.12 9.33 4.44 40 K 0.52 1.00 -0.20 19.46 4.62 40 L 0.12 -0.20 1.00 28.61 4.57 A.1.2 From existing data Using the data from the built-in dataset attitude, simulate a new set of 20 observations drawn from a population with the same means, SDs and correlations for each column as the original data. dat_r &lt;- cor(attitude) dat_mu &lt;- summarise_all(attitude, mean) %&gt;% t() dat_sd &lt;- summarise_all(attitude, sd) %&gt;% t() ex2 &lt;- rnorm_multi(20, mu = dat_mu, sd = dat_sd,r = dat_r) get_params(ex2) n var rating complaints privileges learning raises critical advance mean sd 20 rating 1.00 0.68 0.39 0.38 0.37 0.26 0.06 62.73 8.19 20 complaints 0.68 1.00 0.50 0.18 0.51 0.34 -0.05 64.82 9.84 20 privileges 0.39 0.50 1.00 0.29 0.34 -0.03 0.10 50.06 10.68 20 learning 0.38 0.18 0.29 1.00 0.59 0.01 0.64 55.90 11.33 20 raises 0.37 0.51 0.34 0.59 1.00 0.30 0.60 63.06 10.82 20 critical 0.26 0.34 -0.03 0.01 0.30 1.00 -0.19 76.67 10.22 20 advance 0.06 -0.05 0.10 0.64 0.60 -0.19 1.00 43.89 12.71 A.1.3 2b Create a dataset with a between-subject factor of “pet” having two levels, “cat,” and “dog.” The DV is “happiness” score. There are 20 cat-owners with a mean happiness score of 10 (SD = 3) and there are 30 dog-owners with a mean happiness score of 11 (SD = 3). dat2b &lt;- sim_design( between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;)), dv = &quot;happiness&quot;, n = list(cat = 20, dog = 30), mu = list(cat = 10, dog = 11), sd = 3 ) get_params(dat2b, between = &quot;pet&quot;) pet n mean sd cat 20 10.21 2.95 dog 30 11.17 2.69 A.1.4 3w Create a dataset of 20 observations with 1 within-subject variable (“condition”) having 3 levels (“A,” “B,” “C”) with means of 10, 20 and 30 and SD of 5. The correlations between each level have r = 0.4. The dataset should look like this: id condition score S01 A 9.17 … … … S20 A 11.57 S01 B 18.44 … … … S20 B 20.04 S01 C 35.11 … … … S20 C 29.16 dat3w &lt;- sim_design( within = list(condition = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)), n = 20, mu = c(10, 20, 30), sd = 5, r = .4, dv = &quot;score&quot;, long = TRUE ) get_params(dat3w) n var A B C mean sd 20 A 1.00 0.47 0.43 8.59 4.70 20 B 0.47 1.00 0.21 20.65 5.97 20 C 0.43 0.21 1.00 31.00 3.29 A.1.5 2w*2w Create a dataset with 50 observations of 2 within-subject variables (“A” and “B”) each having 2 levels. The mean for all cells is 10 and the SD is 2. The dataset should have 20 subjects. The correlations look like this: A1_B1 A1_B2 A2_B1 A2_B2 A1_B1 1.0 0.5 0.5 0.2 A1_B2 0.5 1.0 0.2 0.5 A2_B1 0.5 0.2 1.0 0.5 A2_B2 0.2 0.5 0.5 1.0 dat2w2w &lt;- sim_design( within = c(2,2), n = 50, mu = 10, sd = 2, r = c(.5, .5, .2, .2, .5, .5) ) get_params(dat2w2w) n var A1_B1 A1_B2 A2_B1 A2_B2 mean sd 50 A1_B1 1.00 0.41 0.45 0.13 10.67 2.03 50 A1_B2 0.41 1.00 -0.08 0.37 10.00 2.15 50 A2_B1 0.45 -0.08 1.00 0.40 10.44 2.16 50 A2_B2 0.13 0.37 0.40 1.00 9.95 2.11 A.1.6 2w*3b Create a dataset with a between-subject factor of “pet” having 3 levels (“cat,” “dog,” and “ferret”) and a within-subject factor of “time” having 2 levels (“pre” and “post”). The N in each group should be 10. Means are: cats: pre = 10, post = 12 dogs: pre = 14, post = 16 ferrets: pre = 18, post = 20 SDs are all 5 and within-cell correlations are all 0.25. mu &lt;- data.frame( cat = c(10, 12), dog = c(14, 16), ferret = c(18, 20) ) dat2w3b &lt;- sim_design( within = list(time = c(&quot;pre&quot;, &quot;post&quot;)), between = list(pet = c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;)), n = 10, mu = mu, sd = 5, r = 0.25 ) get_params(dat2w3b) pet n var pre post mean sd cat 10 pre 1.00 0.49 8.68 4.19 cat 10 post 0.49 1.00 10.47 6.35 dog 10 pre 1.00 0.04 13.60 5.16 dog 10 post 0.04 1.00 15.52 4.52 ferret 10 pre 1.00 0.08 15.17 4.73 ferret 10 post 0.08 1.00 17.66 5.88 A.1.7 Replications Create 5 datasets with a 2b*2b design, 30 participants in each cell. Each cell’s mean should be 0, except A1_B1, which should be 0.5. The SD should be 1. Make the resulting data in long format. dat2b2b &lt;- sim_design( between = c(2,2), n = 30, mu = c(0.5, 0, 0, 0), rep = 5, long = TRUE ) A.1.8 Power Simulate 100 datasets like the one above and use lm() or afex::aov_ez() to look at the interaction between A and B. What is the power of this design? # simulate 100 datasets dat2b2b_100 &lt;- sim_design( between = c(2, 2), n = 30, mu = c(0.5, 0, 0, 0), rep = 100, long = TRUE ) # linear model version analyse_lm &lt;- function(data) { lm(y ~ A*B, data = data) %&gt;% broom::tidy() %&gt;% mutate(term = factor(term, levels = term)) } ana_lm &lt;- dat2b2b_100 %&gt;% mutate(analysis = map(data, analyse_lm)) %&gt;% select(-data) %&gt;% unnest(analysis) ana_lm %&gt;% group_by(term) %&gt;% summarise(power = mean(p.value &lt; .05), .groups = &quot;drop&quot;) term power (Intercept) 0.77 AA2 0.52 BB2 0.49 AA2:BB2 0.33 # anova version afex::set_sum_contrasts() # avoids annoying afex message ## setting contr.sum globally: options(contrasts=c(&#39;contr.sum&#39;, &#39;contr.poly&#39;)) afex_options(include_aov = FALSE) # runs faster afex_options(es_aov = &quot;pes&quot;) # changes effect size measure to partial eta squared analyse_aov &lt;- function(data) { a &lt;- afex::aov_ez(id = &quot;id&quot;, dv = &quot;y&quot;, between = c(&quot;A&quot;, &quot;B&quot;), data = data) as_tibble(a$anova_table, rownames = &quot;term&quot;) %&gt;% mutate(term = factor(term, levels = term)) %&gt;% rename(p.value = `Pr(&gt;F)`) } ana_aov &lt;- dat2b2b_100 %&gt;% mutate(analysis = map(data, analyse_aov)) %&gt;% select(-data) %&gt;% unnest(analysis) ana_aov %&gt;% group_by(term) %&gt;% summarise(power = mean(p.value &lt; .05), .groups = &quot;drop&quot;) term power A 0.23 B 0.21 A:B 0.33 A.2 Calorie Placement Re-Simulation A.2.1 Data Source We will be replicating some of the re-analyses in Francis &amp; Thunell’s (2020) Meta-Psychology paper: Excess success in “Don’t count calorie labeling out: Calorie counts on the left side of menu items lead to lower calorie food choices.” They ran power analyses for all 6 studies in Dallas, Liu, and Ubel’s (2019) study showing that people order food with significantly fewer calories when the calorie count was placed to the left of the item than to the right (or having no calorie label). They then used these power estimates to calculate the probability of all 6 out of 6 studies being significant, given the observed power of each study. Re-analysis Re-analysis code Original paper Table 1 of the re-analysis paper provides all of the parameters we will need. A.2.2 Study 2 We’ll start with S2 because the analysis is very straightforward. It’s a between-subjects design, where 143 subjects saw calorie placement on the left and their mean calories ordered were 1249.83 (SD = 449.07), while 132 subjects saw calorie placement on the right and their mean calories ordered were 1362.31 (SD = 447.35). Let’s first simulate a single data table with these parameters and set up our analysis. s2 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;)), mu = c(left = 1249.83, right = 1362.31), sd = c(left = 449.07, right = 447.35), n = c(left = 143, right = 132), dv = &quot;calories&quot; ) Wrap the analysis in a function using the tidy() function from {broom} to get the results in a tidy table. Check that it works by running it on the single data set above. s2_analyse &lt;- function(data) { t.test(calories ~ placement, data = data) %&gt;% broom::tidy() } s2_analyse(s2) estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high method alternative -134.2927 1182.723 1317.016 -2.376637 0.0181663 270.9239 -245.5381 -23.04728 Welch Two Sample t-test two.sided Now, simulate the data 1000 times. s2 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;)), mu = c(left = 1249.83, right = 1362.31), sd = c(left = 449.07, right = 447.35), n = c(left = 143, right = 132), dv = &quot;calories&quot;, rep = 1000 ) Run the analysis on each data set. s2_sim &lt;- s2 %&gt;% mutate(analysis = map(data, s2_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) head(s2_sim) rep estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high method alternative 1 -83.51288 1268.786 1352.299 -1.774903 0.0770381 270.5825 -176.1476 9.121849 Welch Two Sample t-test two.sided 2 -114.97521 1263.464 1378.439 -2.181833 0.0299779 271.9809 -218.7203 -11.230099 Welch Two Sample t-test two.sided 3 -85.44596 1255.420 1340.866 -1.573587 0.1167434 272.4557 -192.3471 21.455179 Welch Two Sample t-test two.sided 4 -116.93164 1218.279 1335.211 -2.074587 0.0389873 265.7669 -227.9081 -5.955226 Welch Two Sample t-test two.sided 5 -139.76904 1247.966 1387.735 -2.575934 0.0105253 271.9315 -246.5912 -32.946843 Welch Two Sample t-test two.sided 6 -72.69624 1295.543 1368.239 -1.311121 0.1910297 247.9852 -181.9011 36.508633 Welch Two Sample t-test two.sided Summarise the p.value column to get power. s2_power &lt;- s2_sim %&gt;% mutate(sig = p.value &lt; .05) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) Compare this value (0.539) with the value in the paper (0.5426). A.2.3 Study 1 Study 1 is a little more complicated because the design includes a “no label” condition, so the decision rule for supporting the hypothesis is more complicated. The data simulation is relatively straightforward, though. s1 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;, &quot;none&quot;)), mu = c(654.53, 865.41, 914.34), sd = c(390.45, 517.26, 560.94), n = c(45, 54, 50), dv = &quot;calories&quot; ) Set up the analysis. Here, we really just care about three p=values, so we’ll just return those. We can use a function from the {emmeans} package to check the two pairwise comparisons. afex::set_sum_contrasts() # avoids annoying afex message on each run ## setting contr.sum globally: options(contrasts=c(&#39;contr.sum&#39;, &#39;contr.poly&#39;)) afex_options(include_aov = TRUE) # we need aov for lsmeans s1_analyse &lt;- function(data) { # main effect of placement a &lt;- afex::aov_ez( id = &quot;id&quot;, dv = &quot;calories&quot;, between = &quot;placement&quot;, data = data ) # contrasts e &lt;- emmeans(a, &quot;placement&quot;) c1 &lt;- list(lr = c(-0.5, 0.5, 0), ln = c(-0.5, 0, 0.5)) b &lt;- contrast(e, c1, adjust = &quot;holm&quot;) %&gt;% broom::tidy() data.frame( p_all = a$anova_table$`Pr(&gt;F)`[[1]], p_1 = b$adj.p.value[[1]], p_2 = b$adj.p.value[[2]] ) } s1_analyse(s1) p_all p_1 p_2 0.0418833 0.1474684 0.0239774 Let’s just replicate this 100 times so the simulation doesn’t take too long to run at first. We can always increase it later after we’ve run some sense checks. s1 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;, &quot;none&quot;)), mu = c(654.53, 865.41, 914.34), sd = c(390.45, 517.26, 560.94), n = c(45, 54, 50), dv = &quot;calories&quot;, rep = 100 ) Run the analysis on each data set. s1_sim &lt;- s1 %&gt;% mutate(analysis = map(data, s1_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) head(s1_sim) rep p_all p_1 p_2 1 0.0034317 0.0086018 0.0027807 2 0.2595953 0.2328832 0.2328832 3 0.0004448 0.0001797 0.0506550 4 0.0676437 0.0931488 0.0487033 5 0.0169225 0.0235099 0.0235099 6 0.0650196 0.1093398 0.0435229 Calculating power is a little trickier here, as all three p-values need to be significant here to support the hypothesis. s1_power &lt;- s1_sim %&gt;% mutate(sig = (p_all &lt; .05) &amp; (p_1 &lt; .05) &amp; (p_2 &lt; .05) ) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) Compare this value (0.42) with the value in the paper (0.4582). A.2.4 Study 3 Now you can use the pattern from Study 1 to analyse the data for Study 3. We’ll start with the repeated data set. s3 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;, &quot;none&quot;)), mu = c(1428.24, 1308.66, 1436.79), sd = c(377.02, 420.14, 378.47), n = c(85, 86, 81), dv = &quot;calories&quot;, rep = 100 ) These data were collected in the Hebrew language, which reads right to left, so the paired contrasts will be different. s3_analyse &lt;- function(data) { # main effect of placement a &lt;- afex::aov_ez( id = &quot;id&quot;, dv = &quot;calories&quot;, between = &quot;placement&quot;, data = data ) # contrasts (reversed) e &lt;- emmeans(a, &quot;placement&quot;) c1 &lt;- list(rl = c(0.5, -0.5, 0), ln = c(0, -0.5, 0.5)) b &lt;- contrast(e, c1, adjust = &quot;holm&quot;) %&gt;% broom::tidy() data.frame( p_all = a$anova_table$`Pr(&gt;F)`[[1]], p_1 = b$adj.p.value[[1]], p_2 = b$adj.p.value[[2]] ) } Run the analysis on each data set. s3_sim &lt;- s3 %&gt;% mutate(analysis = map(data, s3_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) head(s3_sim) rep p_all p_1 p_2 1 0.0262845 0.0166075 0.0750064 2 0.0549322 0.0659798 0.0659798 3 0.0291340 0.1503155 0.0159775 4 0.0145949 0.0073671 0.1366318 5 0.0122501 0.0499609 0.0073854 6 0.0350654 0.0277263 0.0561030 s3_power &lt;- s3_sim %&gt;% mutate(sig = (p_all &lt; .05) &amp; (p_1 &lt; .05) &amp; (p_2 &lt; .05) ) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) Compare this value (0.31) with the value in the paper (0.3626). A.2.5 Study S1 Now you can use the pattern from Study 2 to analyse the data for Study S1. You can even reuse the analysis function s2_analyse! ss1 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;)), mu = c(left = 185.94, right = 215.73), sd = c(left = 93.92, right = 95.33), n = c(left = 99, right = 77), dv = &quot;calories&quot;, rep = 1000 ) ss1_sim &lt;- ss1 %&gt;% mutate(analysis = map(data, s2_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) ss1_power &lt;- ss1_sim %&gt;% mutate(sig = p.value &lt; .05) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) A.2.6 Study S2 Now you can use the pattern from Study 1 to analyse the data for Study S2. You can even reuse the analysis function s1_analyse! ss2 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;, &quot;none&quot;)), mu = c(1182.15, 1302.23, 1373.74), sd = c(477.60, 434.41, 475.77), n = c(139, 141, 151), dv = &quot;calories&quot;, rep = 100 ) ss2_sim &lt;- ss2 %&gt;% mutate(analysis = map(data, s1_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) ss2_power &lt;- ss2_sim %&gt;% mutate(sig = (p_all &lt; .05) &amp; (p_1 &lt; .05) &amp; (p_2 &lt; .05) ) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) A.2.7 Study S3 Now you can use the pattern from Study 1 to analyse the data for Study S3. ss3 &lt;- sim_design( between = list(placement = c(&quot;left&quot;, &quot;right&quot;, &quot;none&quot;)), mu = c(1302.03, 1373.15, 1404.35), sd = c(480.02, 442.49, 422.03), n = c(336, 337, 333), dv = &quot;calories&quot;, rep = 100 ) ss3_sim &lt;- ss3 %&gt;% mutate(analysis = map(data, s1_analyse)) %&gt;% select(-data) %&gt;% unnest(analysis) ss3_power &lt;- ss3_sim %&gt;% mutate(sig = (p_all &lt; .05) &amp; (p_1 &lt; .05) &amp; (p_2 &lt; .05) ) %&gt;% summarise(power = mean(sig)) %&gt;% pull(power) A.2.8 Conclusion Now that you’ve calculated power for each of the 6 studies, just multiply the 6 power values together to get the probability that all 6 studies will be significant. power_table &lt;- tribble( ~study, ~power_ft, ~ power_my, &quot;1&quot;, 0.4582, s1_power, &quot;2&quot;, 0.5426, s2_power, &quot;3&quot;, 0.3626, s3_power, &quot;S1&quot;, 0.5358, ss1_power, &quot;S2&quot;, 0.5667, ss2_power, &quot;S3&quot;, 0.4953, ss3_power ) power_table study power_ft power_my 1 0.4582 0.420 2 0.5426 0.539 3 0.3626 0.310 S1 0.5358 0.547 S2 0.5667 0.510 S3 0.4953 0.420 The reduce() function from {purrr} applies a function sequentially over a vector, so can give up the product of all the values in the power columns. prob_ft &lt;- purrr::reduce(power_table$power_ft, `*`) prob_my &lt;- purrr::reduce(power_table$power_my, `*`) The Francis &amp; Thunell paper showed a 0.01 probability of getting 6 of 6 studies significant. Our re-simulation showed a 0.01 probability. "]]
